{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I called SNPs across all species. Now, for each species, find the major allele to create a pseudo reference where the original loblolly reference allele is replaced by the species-specific major allele.\n",
    "\n",
    "Afterward, remap and call SNPs for each species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 56\n"
     ]
    }
   ],
   "source": [
    "from pythonimports import *\n",
    "DIR = '/lu213/brandon.lind/data/BURT/data'\n",
    "vcfdir = op.join(DIR, '04_vcfs')\n",
    "lview,dview = get_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first set all species to their own vcf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1135, 'T-AR-2-7')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of samples\n",
    "samp2pool = pklload(op.join(DIR, 'samp2pool.pkl'))\n",
    "len(samp2pool), keys(samp2pool)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T 432\n",
      "G 171\n",
      "P 306\n",
      "E 226\n"
     ]
    }
   ],
   "source": [
    "# assign samples to species\n",
    "species = defaultdict(list)\n",
    "for samp in samp2pool:\n",
    "    spp = samp.split(\"-\")[0]\n",
    "    species[spp].append(samp)\n",
    "for spp,samplist in species.items():\n",
    "    print(spp, len(samplist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T /lu213/brandon.lind/data/BURT/data/04_vcfs/T_samplist.txt\n",
      "G /lu213/brandon.lind/data/BURT/data/04_vcfs/G_samplist.txt\n",
      "P /lu213/brandon.lind/data/BURT/data/04_vcfs/P_samplist.txt\n",
      "E /lu213/brandon.lind/data/BURT/data/04_vcfs/E_samplist.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write samples to species-specific files to use in `bcftools view` call\n",
    "files = {}\n",
    "for spp,samplist in species.items():\n",
    "    file = op.join(vcfdir, f\"{spp}_samplist.txt\")\n",
    "    with open(file, 'w') as o:\n",
    "        o.write('\\n'.join(samplist))\n",
    "    print(spp, file)\n",
    "    files[spp] = file\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./lu213/brandon.lind/data/BURT/data/04_vcfs/T_filt_cmd.sh\n",
      "./lu213/brandon.lind/data/BURT/data/04_vcfs/G_filt_cmd.sh\n",
      "./lu213/brandon.lind/data/BURT/data/04_vcfs/P_filt_cmd.sh\n",
      "./lu213/brandon.lind/data/BURT/data/04_vcfs/E_filt_cmd.sh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get bcftools/vcftools command to filter allsnps.vcf for species sample list, biallelic SNPs, \n",
    "    # with min ALT freq of 0.7 and max missing data of 50%\n",
    "    # the reason I'm using AF > 0.7 is because these are the sites I will want to replace in the reference\n",
    "# write commands to an executable file\n",
    "vcf = op.join(vcfdir, 'TotalRawSNPs.vcf.gz')\n",
    "vcftools = '/data/programs/vcftools_0.1.13/bin/vcftools'\n",
    "bcftools = '/data/programs/bcftools-1.9/bcftools'\n",
    "filtfiles = []\n",
    "for spp,file in files.items():\n",
    "    sppvcf = vcf.replace('.vcf.gz', f'_alt-filtered_{spp}.vcf.gz')\n",
    "    # use bcftools to subset samples, then vcftools to do the filtering\n",
    "    cmd = f\"{bcftools} view \\\n",
    "--samples-file {file} {vcf} \\\n",
    "-Oz | {vcftools} --gzvcf - \\\n",
    "--non-ref-af 0.7 \\\n",
    "--max-missing 0.5 \\\n",
    "--minQ 20 \\\n",
    "--recode \\\n",
    "--recode-INFO-all \\\n",
    "--remove-indels \\\n",
    "--min-alleles 2 \\\n",
    "--max-alleles 2 \\\n",
    "--stdout | bgzip -c > {sppvcf}\"\n",
    "    cmdfile = op.join(vcfdir, f'{spp}_filt_cmd.sh')\n",
    "    with open(cmdfile, 'w') as o:\n",
    "        o.write(cmd)\n",
    "    !chmod +x $cmdfile\n",
    "    print(f'.{cmdfile}')\n",
    "    filtfiles.append(sppvcf)\n",
    "len(filtfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I executed these files in separate terminal windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert filtered vcfs to .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/programs/gatk-4.1.0.0/gatk IndexFeatureFile -F /lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_T.vcf.gz \n",
      "\n",
      "/data/programs/gatk-4.1.0.0/gatk IndexFeatureFile -F /lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_G.vcf.gz \n",
      "\n",
      "/data/programs/gatk-4.1.0.0/gatk IndexFeatureFile -F /lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_P.vcf.gz \n",
      "\n",
      "/data/programs/gatk-4.1.0.0/gatk IndexFeatureFile -F /lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_E.vcf.gz \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# index files\n",
    "gatk = '/data/programs/gatk-4.1.0.0/gatk'\n",
    "for f in filtfiles:\n",
    "    cmd = f'{gatk} IndexFeatureFile -F {f}'\n",
    "    print(cmd, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "picard UpdateVcfSequenceDictionary I=/lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_T.vcf.gz O=/lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_T_added-lengths.vcf.gz SEQUENCE_DICTIONARY=/data/database/Pita_db/Pita2_stitched/pita2_stitch_v2.fa \n",
      "\n",
      "picard UpdateVcfSequenceDictionary I=/lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_G.vcf.gz O=/lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_G_added-lengths.vcf.gz SEQUENCE_DICTIONARY=/data/database/Pita_db/Pita2_stitched/pita2_stitch_v2.fa \n",
      "\n",
      "picard UpdateVcfSequenceDictionary I=/lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_P.vcf.gz O=/lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_P_added-lengths.vcf.gz SEQUENCE_DICTIONARY=/data/database/Pita_db/Pita2_stitched/pita2_stitch_v2.fa \n",
      "\n",
      "picard UpdateVcfSequenceDictionary I=/lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_E.vcf.gz O=/lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_E_added-lengths.vcf.gz SEQUENCE_DICTIONARY=/data/database/Pita_db/Pita2_stitched/pita2_stitch_v2.fa \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add in contig lengths so VariantsToTable works below\n",
    "\n",
    "# I used a new conda env (\"picard\") to install picard (Version:2.23.8) via bioconda\n",
    "    # I only used this env for this command.\n",
    "ref = '/data/database/Pita_db/Pita2_stitched/pita2_stitch_v2.fa'\n",
    "updated = []\n",
    "for f in filtfiles:\n",
    "    out = f.replace(\".vcf.gz\", \"_added-lengths.vcf.gz\")\n",
    "    cmd = f\"picard UpdateVcfSequenceDictionary I={f} O={out} SEQUENCE_DICTIONARY={ref}\"\n",
    "    print(cmd, '\\n')\n",
    "    updated.append(out)\n",
    "len(updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/programs/gatk-4.1.0.0/gatk IndexFeatureFile -F /lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_T_added-lengths.vcf.gz \n",
      "\n",
      "/data/programs/gatk-4.1.0.0/gatk IndexFeatureFile -F /lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_G_added-lengths.vcf.gz \n",
      "\n",
      "/data/programs/gatk-4.1.0.0/gatk IndexFeatureFile -F /lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_P_added-lengths.vcf.gz \n",
      "\n",
      "/data/programs/gatk-4.1.0.0/gatk IndexFeatureFile -F /lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_E_added-lengths.vcf.gz \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# index the new files\n",
    "for f in updated:\n",
    "    cmd = f'{gatk} IndexFeatureFile -F {f}'\n",
    "    print(cmd, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/programs/gatk-4.1.0.0/gatk VariantsToTable --variant /lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_T_added-lengths.vcf.gz -F CHROM -F POS -F REF -F ALT -O /lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_T_added-lengths.txt \n",
      "\n",
      "/data/programs/gatk-4.1.0.0/gatk VariantsToTable --variant /lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_G_added-lengths.vcf.gz -F CHROM -F POS -F REF -F ALT -O /lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_G_added-lengths.txt \n",
      "\n",
      "/data/programs/gatk-4.1.0.0/gatk VariantsToTable --variant /lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_P_added-lengths.vcf.gz -F CHROM -F POS -F REF -F ALT -O /lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_P_added-lengths.txt \n",
      "\n",
      "/data/programs/gatk-4.1.0.0/gatk VariantsToTable --variant /lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_E_added-lengths.vcf.gz -F CHROM -F POS -F REF -F ALT -O /lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_E_added-lengths.txt \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert to tables\n",
    "outfiles = []\n",
    "for f in updated:\n",
    "    outfile = f.replace(\".vcf.gz\", \".txt\")\n",
    "    cmd = f'{gatk} VariantsToTable --variant {f} -F CHROM -F POS -F REF -F ALT -O {outfile}'\n",
    "    print(cmd, '\\n')\n",
    "    outfiles.append(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i manually checked that the new txt files have the same number of sites as the vcf.gz files\n",
    "    # zcat vcf | grep -v \"#\" | wc -l\n",
    "    # wc -l txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create psuedo genomes\n",
    "\n",
    "For all of the sites that I've filtered on a per-species basis above, replace the REF allele with the ALT allele in the reference and save to a new ref.fa file (ie a psuedogenome.fa)\n",
    "\n",
    "modified from https://github.com/poojasingh09/pseudogenome-maker/blob/master/pseudogenome_maker.sh\n",
    "\n",
    "credit also to Mengmeng Lu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first create a tabbed ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seqkit fx2tab /data/database/Pita_db/Pita2_stitched/pita2_stitch_v2.fa > /data/database/Pita_db/Pita2_stitched/pita2_stitch_v2.tab\n"
     ]
    }
   ],
   "source": [
    "# convert .fa to .tab\n",
    "tabbed_ref = ref.replace('.fa', '.tab')\n",
    "print(f'seqkit fx2tab {ref} > {tabbed_ref}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 23.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# double check that ref and alt differ for all loci in the txt files\n",
    "    # they should since the ALT is what I want to replace in the REF\n",
    "for f in nb(outfiles):\n",
    "    df = pd.read_table(f)\n",
    "    assert sum(df['REF']==df['ALT']) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awk 'FILENAME==\"/data/database/Pita_db/Pita2_stitched/pita2_stitch_v2.tab\" {fa[$1]=$2; next} {fa[$1]=substr(fa[$1], 1, $2-1) $4 substr(fa[$1], $2+1, length(fa[$1])-$2)} END {for (id in fa){print \">\" id \"\\n\" fa[id]}}' /data/database/Pita_db/Pita2_stitched/pita2_stitch_v2.tab /lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_T_added-lengths.txt > /lu213/brandon.lind/data/BURT/data/04_vcfs/psuedogenome_T.fa \n",
      "\n",
      "awk 'FILENAME==\"/data/database/Pita_db/Pita2_stitched/pita2_stitch_v2.tab\" {fa[$1]=$2; next} {fa[$1]=substr(fa[$1], 1, $2-1) $4 substr(fa[$1], $2+1, length(fa[$1])-$2)} END {for (id in fa){print \">\" id \"\\n\" fa[id]}}' /data/database/Pita_db/Pita2_stitched/pita2_stitch_v2.tab /lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_G_added-lengths.txt > /lu213/brandon.lind/data/BURT/data/04_vcfs/psuedogenome_G.fa \n",
      "\n",
      "awk 'FILENAME==\"/data/database/Pita_db/Pita2_stitched/pita2_stitch_v2.tab\" {fa[$1]=$2; next} {fa[$1]=substr(fa[$1], 1, $2-1) $4 substr(fa[$1], $2+1, length(fa[$1])-$2)} END {for (id in fa){print \">\" id \"\\n\" fa[id]}}' /data/database/Pita_db/Pita2_stitched/pita2_stitch_v2.tab /lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_P_added-lengths.txt > /lu213/brandon.lind/data/BURT/data/04_vcfs/psuedogenome_P.fa \n",
      "\n",
      "awk 'FILENAME==\"/data/database/Pita_db/Pita2_stitched/pita2_stitch_v2.tab\" {fa[$1]=$2; next} {fa[$1]=substr(fa[$1], 1, $2-1) $4 substr(fa[$1], $2+1, length(fa[$1])-$2)} END {for (id in fa){print \">\" id \"\\n\" fa[id]}}' /data/database/Pita_db/Pita2_stitched/pita2_stitch_v2.tab /lu213/brandon.lind/data/BURT/data/04_vcfs/TotalRawSNPs_alt-filtered_E_added-lengths.txt > /lu213/brandon.lind/data/BURT/data/04_vcfs/psuedogenome_E.fa \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# replace the REF allele in reference with the ALT allele (AF > 0.7) for each species\n",
    "for f in outfiles:\n",
    "    spp = f.split(\"_\")[-2]\n",
    "    pseudo = op.join(vcfdir, f'psuedogenome_{spp}.fa')\n",
    "    cmd = '''awk 'FILENAME==\"%(tabbed_ref)s\" {fa[$1]=$2; next} {fa[$1]=substr(fa[$1], 1, $2-1) $4 substr(fa[$1], $2+1, length(fa[$1])-$2)} END {for (id in fa){print \">\" id \"\\\\n\" fa[id]}}' %(tabbed_ref)s %(f)s > %(pseudo)s''' % locals()\n",
    "    print(cmd, '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
